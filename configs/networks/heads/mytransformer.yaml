head_network:
  name: 'mytransformer'
  embed_dim: 128  # 384 for small, 768 for base
  num_heads: 4  # 12
  mlp_ratio: 4  # used instead of explicit ff_dim
  qkv_bias: true
  num_layers: 6  # 12
  ape_dropout_rate: 0.0
  attn_dropout_rate: 0.0
  attn_proj_dropout_rate: 0.0
  ff_dropout_rate: 0.0
  init_weights_cfg:
    type: 'xavier'  # choices: 'xavier', 'kaiming', 'trunc_normal', 'normal'
    distribution: 'uniform' # choices: 'uniform', 'normal'; applies if type is 'xavier' or 'kaiming'
