head_network:
  name: 'mlp'
  embed_dim: 128
  hidden_dim: 128
  activation: 'relu'
  # n_layers: 2