model:
  backbone: 'transformer'  # choices: 'transformer'
  head: 'transformer'  # choices: 'transformer'
  pretrained: null
  n_tasks: 400    # NOTE: this is used for the task embedding (i.e., to inform the model through an embedding of which tasks to consider)
  task_embedding:
    enabled: false
    task_embedding_dim: ${resolve_if_then_else:${model.task_embedding.enabled},128}
  output_embed_dim: 128
  training_hparams:
    optimizer: 'Adam' # it can be: Adam, AdamW, SGD
    scheduler: 'ReduceLROnPlateau' # it can be: ReduceLROnPlateau, StepLR, MultiStepLR, ExponentialLR, CosineAnnealingLR
    lr: 0.001
    wd: 0.001